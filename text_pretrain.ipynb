{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from datetime import datetime\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T10:20:59.776723400Z",
     "start_time": "2023-11-12T10:20:56.231041800Z"
    }
   },
   "id": "e6171b353dbb7cf7"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# 设置文件路径和参数\n",
    "file_path = 'entity_description.txt'\n",
    "batch_size = 16\n",
    "max_length = 512\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T10:27:46.186669100Z",
     "start_time": "2023-11-12T10:27:46.172658200Z"
    }
   },
   "id": "ec62483e6c9090e0"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# 加载BERT模型和tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 读取文本文件\n",
    "data = pd.read_csv(file_path, sep='\\t', header=None, usecols=[1])\n",
    "texts = data[1].tolist()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T10:27:50.657154700Z",
     "start_time": "2023-11-12T10:27:48.268916900Z"
    }
   },
   "id": "7b992dba19a9b1b4"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 创建特征提取函数\n",
    "def extract_features(texts):\n",
    "    features = []\n",
    "    num_batches = len(texts) // batch_size\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        batch_texts = texts[i * batch_size: (i + 1) * batch_size]\n",
    "        encoded_inputs = tokenizer(batch_texts, padding='longest', truncation=True, max_length=max_length, return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoded_inputs)\n",
    "            features.append(outputs.last_hidden_state[:, 0, :].numpy())\n",
    "\n",
    "        # 打印进度\n",
    "        if (i + 1) % 10 == 0:\n",
    "            timestamp = datetime.now().strftime(\"[%H:%M:%S]\")\n",
    "            completed_rows = (i + 1) * batch_size\n",
    "            total_rows = num_batches * batch_size\n",
    "            print(f\"{timestamp} 已完成 {i + 1} 批次，{completed_rows}/{total_rows} 行\")\n",
    "\n",
    "    print(\"特征提取完成\")\n",
    "    return np.concatenate(features)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T10:21:10.716162700Z",
     "start_time": "2023-11-12T10:21:10.705149400Z"
    }
   },
   "id": "9934346c1fc85f0a"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:28:42] 已完成 10 批次，160/12832 行\n",
      "[18:29:23] 已完成 20 批次，320/12832 行\n",
      "[18:30:07] 已完成 30 批次，480/12832 行\n",
      "[18:30:52] 已完成 40 批次，640/12832 行\n",
      "[18:31:37] 已完成 50 批次，800/12832 行\n",
      "[18:32:22] 已完成 60 批次，960/12832 行\n",
      "[18:33:06] 已完成 70 批次，1120/12832 行\n",
      "[18:33:53] 已完成 80 批次，1280/12832 行\n",
      "[18:34:37] 已完成 90 批次，1440/12832 行\n",
      "[18:35:21] 已完成 100 批次，1600/12832 行\n",
      "[18:36:06] 已完成 110 批次，1760/12832 行\n",
      "[18:36:53] 已完成 120 批次，1920/12832 行\n",
      "[18:37:40] 已完成 130 批次，2080/12832 行\n",
      "[18:38:22] 已完成 140 批次，2240/12832 行\n",
      "[18:39:06] 已完成 150 批次，2400/12832 行\n",
      "[18:39:52] 已完成 160 批次，2560/12832 行\n",
      "[18:40:38] 已完成 170 批次，2720/12832 行\n",
      "[18:41:24] 已完成 180 批次，2880/12832 行\n",
      "[18:42:10] 已完成 190 批次，3040/12832 行\n",
      "[18:42:53] 已完成 200 批次，3200/12832 行\n",
      "[18:43:39] 已完成 210 批次，3360/12832 行\n",
      "[18:44:24] 已完成 220 批次，3520/12832 行\n",
      "[18:45:06] 已完成 230 批次，3680/12832 行\n",
      "[18:45:51] 已完成 240 批次，3840/12832 行\n",
      "[18:46:35] 已完成 250 批次，4000/12832 行\n",
      "[18:47:19] 已完成 260 批次，4160/12832 行\n",
      "[18:48:03] 已完成 270 批次，4320/12832 行\n",
      "[18:48:47] 已完成 280 批次，4480/12832 行\n",
      "[18:49:32] 已完成 290 批次，4640/12832 行\n",
      "[18:50:16] 已完成 300 批次，4800/12832 行\n",
      "[18:51:03] 已完成 310 批次，4960/12832 行\n",
      "[18:51:47] 已完成 320 批次，5120/12832 行\n",
      "[18:52:32] 已完成 330 批次，5280/12832 行\n",
      "[18:53:25] 已完成 340 批次，5440/12832 行\n",
      "[18:54:16] 已完成 350 批次，5600/12832 行\n",
      "[18:55:03] 已完成 360 批次，5760/12832 行\n",
      "[18:55:47] 已完成 370 批次，5920/12832 行\n",
      "[18:56:31] 已完成 380 批次，6080/12832 行\n",
      "[18:57:14] 已完成 390 批次，6240/12832 行\n",
      "[18:58:01] 已完成 400 批次，6400/12832 行\n",
      "[18:58:46] 已完成 410 批次，6560/12832 行\n",
      "[18:59:32] 已完成 420 批次，6720/12832 行\n",
      "[19:00:18] 已完成 430 批次，6880/12832 行\n",
      "[19:01:05] 已完成 440 批次，7040/12832 行\n",
      "[19:01:50] 已完成 450 批次，7200/12832 行\n",
      "[19:02:34] 已完成 460 批次，7360/12832 行\n",
      "[19:03:17] 已完成 470 批次，7520/12832 行\n",
      "[19:04:01] 已完成 480 批次，7680/12832 行\n",
      "[19:04:49] 已完成 490 批次，7840/12832 行\n",
      "[19:05:32] 已完成 500 批次，8000/12832 行\n",
      "[19:06:15] 已完成 510 批次，8160/12832 行\n",
      "[19:07:00] 已完成 520 批次，8320/12832 行\n",
      "[19:07:44] 已完成 530 批次，8480/12832 行\n",
      "[19:08:29] 已完成 540 批次，8640/12832 行\n",
      "[19:09:12] 已完成 550 批次，8800/12832 行\n",
      "[19:09:59] 已完成 560 批次，8960/12832 行\n",
      "[19:10:44] 已完成 570 批次，9120/12832 行\n",
      "[19:11:29] 已完成 580 批次，9280/12832 行\n",
      "[19:12:14] 已完成 590 批次，9440/12832 行\n",
      "[19:12:55] 已完成 600 批次，9600/12832 行\n",
      "[19:13:41] 已完成 610 批次，9760/12832 行\n",
      "[19:14:25] 已完成 620 批次，9920/12832 行\n",
      "[19:15:10] 已完成 630 批次，10080/12832 行\n",
      "[19:15:55] 已完成 640 批次，10240/12832 行\n",
      "[19:16:39] 已完成 650 批次，10400/12832 行\n",
      "[19:17:26] 已完成 660 批次，10560/12832 行\n",
      "[19:18:11] 已完成 670 批次，10720/12832 行\n",
      "[19:18:56] 已完成 680 批次，10880/12832 行\n",
      "[19:19:43] 已完成 690 批次，11040/12832 行\n",
      "[19:20:29] 已完成 700 批次，11200/12832 行\n",
      "[19:21:13] 已完成 710 批次，11360/12832 行\n",
      "[19:21:59] 已完成 720 批次，11520/12832 行\n",
      "[19:22:40] 已完成 730 批次，11680/12832 行\n",
      "[19:23:26] 已完成 740 批次，11840/12832 行\n",
      "[19:24:13] 已完成 750 批次，12000/12832 行\n",
      "[19:25:00] 已完成 760 批次，12160/12832 行\n",
      "[19:25:47] 已完成 770 批次，12320/12832 行\n",
      "[19:26:38] 已完成 780 批次，12480/12832 行\n",
      "[19:27:22] 已完成 790 批次，12640/12832 行\n",
      "[19:28:07] 已完成 800 批次，12800/12832 行\n"
     ]
    }
   ],
   "source": [
    "# 提取特征\n",
    "text_features = extract_features(texts)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T11:28:18.274060600Z",
     "start_time": "2023-11-12T10:28:01.698239Z"
    }
   },
   "id": "52e7da8d483bd0a3"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# 保存特征为pickle文件\n",
    "pickle.dump(text_features, open(\"text_features.pkl\", \"wb\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T11:28:43.628661900Z",
     "start_time": "2023-11-12T11:28:43.571004200Z"
    }
   },
   "id": "9451ce0525ed9e8f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
