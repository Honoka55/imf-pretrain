{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from datetime import datetime"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T14:32:24.506711300Z",
     "start_time": "2023-11-12T14:32:19.831867700Z"
    }
   },
   "id": "ab826c9fa222935c"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 加载BERT模型和tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T14:32:29.469988Z",
     "start_time": "2023-11-12T14:32:26.112040400Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def extract_features(batch_size, text_file, feature_file):\n",
    "    model.eval()  # 切换为评估模式，以避免dropout等影响\n",
    "\n",
    "    data = pd.read_csv(text_file, sep='\\t', encoding='utf-8', header=None, usecols=[1])\n",
    "    texts = data[1].tolist()\n",
    "    num_rows = len(texts)\n",
    "    num_batches = num_rows // batch_size + 1\n",
    "    features = []\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"[%H:%M:%S]\")\n",
    "    print(f'{timestamp} 开始从{text_file}提取特征')\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, len(data))\n",
    "        batch_texts = texts[start_idx:end_idx]\n",
    "        encoded_inputs = tokenizer(batch_texts, padding='longest', truncation=True, return_tensors='pt')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoded_inputs)\n",
    "            pooled_output = outputs.pooler_output\n",
    "            features.append(pooled_output.numpy())\n",
    "\n",
    "        if (i + 1) % 10 == 0 or i == num_batches - 1:\n",
    "            timestamp = datetime.now().strftime(\"[%H:%M:%S]\")\n",
    "            completed_batches = i + 1\n",
    "            completed_rows = (completed_batches - 1) * batch_size + len(batch_texts)\n",
    "            print(\n",
    "                f'{timestamp} 已完成{completed_batches}/{num_batches}批次，{completed_rows}/{num_rows}行')\n",
    "\n",
    "    text_features = np.concatenate(features)\n",
    "    pickle.dump(text_features, open(feature_file, 'wb'))\n",
    "    timestamp = datetime.now().strftime(\"[%H:%M:%S]\")\n",
    "    print(f'{timestamp} 文本特征提取完成，已保存至{feature_file}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T14:46:07.898149Z",
     "start_time": "2023-11-12T14:46:07.884155100Z"
    }
   },
   "id": "b5cc4cfe16712037"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:46:21] 开始从../IMF-Pytorch/datasets/DB15K/entity_description.txt提取特征\n",
      "[22:47:09] 已完成10/803批次，160/12842行\n",
      "[22:47:55] 已完成20/803批次，320/12842行\n",
      "[22:48:39] 已完成30/803批次，480/12842行\n",
      "[22:49:28] 已完成40/803批次，640/12842行\n",
      "[22:50:19] 已完成50/803批次，800/12842行\n",
      "[22:51:09] 已完成60/803批次，960/12842行\n",
      "[22:52:00] 已完成70/803批次，1120/12842行\n",
      "[22:52:51] 已完成80/803批次，1280/12842行\n",
      "[22:53:40] 已完成90/803批次，1440/12842行\n",
      "[22:54:29] 已完成100/803批次，1600/12842行\n",
      "[22:55:21] 已完成110/803批次，1760/12842行\n",
      "[22:56:14] 已完成120/803批次，1920/12842行\n",
      "[22:57:04] 已完成130/803批次，2080/12842行\n",
      "[22:57:52] 已完成140/803批次，2240/12842行\n",
      "[22:58:47] 已完成150/803批次，2400/12842行\n",
      "[22:59:48] 已完成160/803批次，2560/12842行\n",
      "[23:00:42] 已完成170/803批次，2720/12842行\n",
      "[23:01:39] 已完成180/803批次，2880/12842行\n",
      "[23:02:38] 已完成190/803批次，3040/12842行\n",
      "[23:03:31] 已完成200/803批次，3200/12842行\n",
      "[23:04:24] 已完成210/803批次，3360/12842行\n",
      "[23:05:18] 已完成220/803批次，3520/12842行\n",
      "[23:06:06] 已完成230/803批次，3680/12842行\n",
      "[23:07:01] 已完成240/803批次，3840/12842行\n",
      "[23:07:54] 已完成250/803批次，4000/12842行\n",
      "[23:08:46] 已完成260/803批次，4160/12842行\n",
      "[23:09:38] 已完成270/803批次，4320/12842行\n",
      "[23:10:32] 已完成280/803批次，4480/12842行\n",
      "[23:11:24] 已完成290/803批次，4640/12842行\n",
      "[23:12:18] 已完成300/803批次，4800/12842行\n",
      "[23:13:15] 已完成310/803批次，4960/12842行\n",
      "[23:14:06] 已完成320/803批次，5120/12842行\n",
      "[23:14:59] 已完成330/803批次，5280/12842行\n",
      "[23:15:55] 已完成340/803批次，5440/12842行\n",
      "[23:16:49] 已完成350/803批次，5600/12842行\n",
      "[23:17:44] 已完成360/803批次，5760/12842行\n",
      "[23:18:40] 已完成370/803批次，5920/12842行\n",
      "[23:19:31] 已完成380/803批次，6080/12842行\n",
      "[23:20:21] 已完成390/803批次，6240/12842行\n",
      "[23:21:17] 已完成400/803批次，6400/12842行\n",
      "[23:22:08] 已完成410/803批次，6560/12842行\n",
      "[23:23:03] 已完成420/803批次，6720/12842行\n",
      "[23:23:55] 已完成430/803批次，6880/12842行\n",
      "[23:24:50] 已完成440/803批次，7040/12842行\n",
      "[23:25:42] 已完成450/803批次，7200/12842行\n",
      "[23:26:33] 已完成460/803批次，7360/12842行\n",
      "[23:27:25] 已完成470/803批次，7520/12842行\n",
      "[23:28:17] 已完成480/803批次，7680/12842行\n",
      "[23:29:14] 已完成490/803批次，7840/12842行\n",
      "[23:30:03] 已完成500/803批次，8000/12842行\n",
      "[23:30:59] 已完成510/803批次，8160/12842行\n",
      "[23:31:58] 已完成520/803批次，8320/12842行\n",
      "[23:32:53] 已完成530/803批次，8480/12842行\n",
      "[23:33:47] 已完成540/803批次，8640/12842行\n",
      "[23:34:36] 已完成550/803批次，8800/12842行\n",
      "[23:35:28] 已完成560/803批次，8960/12842行\n",
      "[23:36:19] 已完成570/803批次，9120/12842行\n",
      "[23:37:09] 已完成580/803批次，9280/12842行\n",
      "[23:38:00] 已完成590/803批次，9440/12842行\n",
      "[23:38:47] 已完成600/803批次，9600/12842行\n",
      "[23:39:38] 已完成610/803批次，9760/12842行\n",
      "[23:40:33] 已完成620/803批次，9920/12842行\n",
      "[23:41:27] 已完成630/803批次，10080/12842行\n",
      "[23:42:17] 已完成640/803批次，10240/12842行\n",
      "[23:43:07] 已完成650/803批次，10400/12842行\n",
      "[23:43:58] 已完成660/803批次，10560/12842行\n",
      "[23:44:47] 已完成670/803批次，10720/12842行\n",
      "[23:45:38] 已完成680/803批次，10880/12842行\n",
      "[23:46:32] 已完成690/803批次，11040/12842行\n",
      "[23:47:24] 已完成700/803批次，11200/12842行\n",
      "[23:48:14] 已完成710/803批次，11360/12842行\n",
      "[23:49:05] 已完成720/803批次，11520/12842行\n",
      "[23:49:52] 已完成730/803批次，11680/12842行\n",
      "[23:50:43] 已完成740/803批次，11840/12842行\n",
      "[23:51:37] 已完成750/803批次，12000/12842行\n",
      "[23:52:31] 已完成760/803批次，12160/12842行\n",
      "[23:53:23] 已完成770/803批次，12320/12842行\n",
      "[23:54:14] 已完成780/803批次，12480/12842行\n",
      "[23:55:04] 已完成790/803批次，12640/12842行\n",
      "[23:55:55] 已完成800/803批次，12800/12842行\n",
      "[23:56:08] 已完成803/803批次，12842/12842行\n",
      "[23:56:08] 文本特征提取完成，已保存至DB15K/text_features.pkl\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'DB15K'\n",
    "text_file = f'../IMF-Pytorch/datasets/{dataset_name}/entity_description.txt'\n",
    "feature_file = f'{dataset_name}/text_features.pkl'\n",
    "batch_size = 16\n",
    "\n",
    "extract_features(batch_size, text_file, feature_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T15:56:08.113400500Z",
     "start_time": "2023-11-12T14:46:21.791297400Z"
    }
   },
   "id": "6ddfe8bf8bcb145c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
